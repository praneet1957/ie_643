{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6Hn7PDS9mmHgtyBenGem9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praneet1957/ie_643/blob/main/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjVKYW7IUrR4"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import numpy as np\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "device = torch.device(\"cuda\")\r\n",
        "\r\n",
        "class GraphConvolution ( nn.Module ):\r\n",
        "    \"\"\"\r\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__ ( self , in_features , out_features , bias=True ):\r\n",
        "        super ( GraphConvolution , self ).__init__ ()\r\n",
        "        self.in_features = in_features\r\n",
        "        self.out_features = out_features\r\n",
        "        self.weight = Parameter ( torch.FloatTensor ( in_features , out_features ).cuda () )\r\n",
        "        if bias:\r\n",
        "            self.bias = Parameter ( torch.FloatTensor ( out_features ).cuda () )\r\n",
        "        else:\r\n",
        "            self.register_parameter ( 'bias' , None )\r\n",
        "        self.reset_parameters ()\r\n",
        "\r\n",
        "    def reset_parameters ( self ):\r\n",
        "        stdv = 1. / math.sqrt ( self.weight.size ( 1 ) )\r\n",
        "        self.weight.data.uniform_ ( -stdv , stdv )\r\n",
        "        if self.bias is not None:\r\n",
        "            self.bias.data.uniform_ ( -stdv , stdv )\r\n",
        "\r\n",
        "    def forward ( self , input , adj ):\r\n",
        "        support = torch.mm ( input , self.weight )\r\n",
        "        output = torch.spmm ( adj , support )\r\n",
        "        if self.bias is not None:\r\n",
        "            return output + self.bias\r\n",
        "        else:\r\n",
        "            return output\r\n",
        "\r\n",
        "    def __repr__ ( self ):\r\n",
        "        return self.__class__.__name__ + ' (' \\\r\n",
        "               + str ( self.in_features ) + ' -> ' \\\r\n",
        "               + str ( self.out_features ) + ')'\r\n",
        "\r\n",
        "\r\n",
        "class GCN ( nn.Module ):\r\n",
        "    def __init__ ( self , nfeat , nhid , nclass , dropout ):\r\n",
        "        super ( GCN , self ).__init__ ()\r\n",
        "\r\n",
        "        self.gc1 = GraphConvolution ( nfeat , nhid )\r\n",
        "        self.gc2 = GraphConvolution ( nhid , nclass )\r\n",
        "        self.dropout = dropout\r\n",
        "\r\n",
        "    def forward ( self , x , adj ):\r\n",
        "        x = F.relu ( self.gc1 ( x , adj ) )\r\n",
        "        x = F.dropout ( x , self.dropout , training=self.training )\r\n",
        "        x = self.gc2 ( x , adj )\r\n",
        "        # return F.log_softmax(x, dim=1)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class Encoder ( nn.Module ):\r\n",
        "    def __init__ ( self , input_size , cell_size , hidden_size ):\r\n",
        "        \"\"\"\r\n",
        "        cell_size is the size of cell_state.\r\n",
        "        hidden_size is the size of hidden_state, or say the output_state of each step\r\n",
        "        \"\"\"\r\n",
        "        super ( Encoder , self ).__init__ ()\r\n",
        "\r\n",
        "        self.cell_size = cell_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.fl = nn.Linear ( input_size + hidden_size , hidden_size )\r\n",
        "        self.il = nn.Linear ( input_size + hidden_size , hidden_size )\r\n",
        "        self.ol = nn.Linear ( input_size + hidden_size , hidden_size )\r\n",
        "        self.Cl = nn.Linear ( input_size + hidden_size , hidden_size )\r\n",
        "\r\n",
        "    def computeDist ( self , x1 , y1 ):\r\n",
        "        return np.abs ( x1 - y1 )\r\n",
        "        # return sqrt ( pow ( x1 - x2 , 2 ) + pow ( y1 - y2 , 2 ) )\r\n",
        "\r\n",
        "    def computeKNN ( self , curr_dict , ID , k ):\r\n",
        "        import heapq\r\n",
        "        from operator import itemgetter\r\n",
        "\r\n",
        "        ID_x = curr_dict[ ID ]\r\n",
        "        dists = {}\r\n",
        "        for j in range ( len ( curr_dict ) ):\r\n",
        "            if j != ID:\r\n",
        "                dists[ j ] = self.computeDist ( ID_x , curr_dict[ j ] )\r\n",
        "        KNN_IDs = dict ( heapq.nsmallest ( k , dists.items () , key=itemgetter ( 1 ) ) )\r\n",
        "        neighbors = list ( KNN_IDs.keys () )\r\n",
        "\r\n",
        "        return neighbors\r\n",
        "        # return [1,2,3]\r\n",
        "\r\n",
        "    def compute_A ( self , xt ):\r\n",
        "        # return Variable(torch.Tensor(np.ones([xt.shape[0],xt.shape[0]])).cuda())\r\n",
        "        xt = xt.cpu ().detach ().numpy ()\r\n",
        "        A = np.zeros ( [ xt.shape[ 0 ] , xt.shape[ 0 ] ] )\r\n",
        "        for i in range ( len ( xt ) ):\r\n",
        "            #if xt[ i ] is not None:\r\n",
        "            if xt[i][0] and xt[i][1] :\r\n",
        "                neighbors = self.computeKNN ( xt , i , 4 )\r\n",
        "                for neighbor in neighbors:\r\n",
        "                    # if neighbor in labels:\r\n",
        "                    # if idx < labels.index ( neighbor ):\r\n",
        "                    A[ i ][ neighbor ] = 1\r\n",
        "        return Variable ( torch.Tensor ( A ).cuda () )\r\n",
        "\r\n",
        "    def forward ( self , input , Hidden_State , Cell_State ):\r\n",
        "        graph = False\r\n",
        "\r\n",
        "        if graph is True:\r\n",
        "            gcn_feat = [ ]\r\n",
        "            gcn_model = GCN ( nfeat=1 , nhid=16 , nclass=1 , dropout=0.5 )\r\n",
        "            for j in range ( input.shape[ 0 ] ):\r\n",
        "                features = input[ j , : ]\r\n",
        "                gcn_feat.append ( gcn_model ( torch.unsqueeze ( features , dim=1 ) ,\r\n",
        "                                              self.compute_A ( features ) ).cpu ().detach ().numpy () )\r\n",
        "\r\n",
        "            input = Parameter ( torch.FloatTensor ( np.asarray ( gcn_feat ) ).cuda () )\r\n",
        "            input = torch.squeeze ( input )\r\n",
        "        # print(input)\r\n",
        "        combined = torch.cat ( (input , Hidden_State) , 1 )\r\n",
        "        f = torch.sigmoid ( self.fl ( combined ) )\r\n",
        "        i = torch.sigmoid ( self.il ( combined ) )\r\n",
        "        o = torch.sigmoid ( self.ol ( combined ) )\r\n",
        "        C = torch.tanh ( self.Cl ( combined ) )\r\n",
        "        Cell_State = f * Cell_State + i * C\r\n",
        "        Hidden_State = o * torch.tanh ( Cell_State )\r\n",
        "\r\n",
        "        return Hidden_State , Cell_State\r\n",
        "\r\n",
        "    def loop ( self , inputs ):\r\n",
        "        batch_size = inputs.size ( 0 )\r\n",
        "        time_step = inputs.size ( 1 )\r\n",
        "        Hidden_State , Cell_State = self.initHidden ( batch_size )\r\n",
        "        for i in range ( time_step ):\r\n",
        "            Hidden_State , Cell_State = self.forward(torch.squeeze(inputs[:, i:i+1,:]), Hidden_State, Cell_State)\r\n",
        "        return Hidden_State , Cell_State\r\n",
        "\r\n",
        "    def initHidden ( self , batch_size ):\r\n",
        "        Hidden_State = Variable ( torch.zeros ( batch_size , self.hidden_size ).to ( device ) )\r\n",
        "        Cell_State = Variable ( torch.zeros ( batch_size , self.hidden_size ).to ( device ) )\r\n",
        "        return Hidden_State , Cell_State\r\n",
        "\r\n",
        "\r\n",
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, stream, input_size , cell_size , hidden_size, batchsize, timestep):\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "        self.cell_size = cell_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.batch_size = batchsize\r\n",
        "        self.time_step = timestep\r\n",
        "        self.num_mog_params = 5\r\n",
        "        self.sampled_point_size = 2\r\n",
        "        self.stream = stream\r\n",
        "        self.stream_specific_param = self.num_mog_params\r\n",
        "        self.stream_specific_param = input_size if self.stream=='s2' else self.num_mog_params\r\n",
        "        self.fl = nn.Linear ( self.stream_specific_param + hidden_size , hidden_size )\r\n",
        "        self.il = nn.Linear ( self.stream_specific_param + hidden_size , hidden_size )\r\n",
        "        self.ol = nn.Linear ( self.stream_specific_param + hidden_size , hidden_size )\r\n",
        "        self.Cl = nn.Linear ( self.stream_specific_param + hidden_size , hidden_size )\r\n",
        "        self.linear1 = nn.Linear ( cell_size ,  self.stream_specific_param )\r\n",
        "        # self.one_lstm = nn.LSTMCell\r\n",
        "        # self.linear2 = nn.Linear ( self.sampled_point_size ,  hidden_size )\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, input , Hidden_State , Cell_State):\r\n",
        "        graph = False\r\n",
        "\r\n",
        "        if graph is True:\r\n",
        "            gcn_feat = [ ]\r\n",
        "            gcn_model = GCN ( nfeat=1 , nhid=16 , nclass=1 , dropout=0.5 )\r\n",
        "            for j in range ( input.shape[ 0 ] ):\r\n",
        "                features = input[ j , : ]\r\n",
        "                gcn_feat.append ( gcn_model ( torch.unsqueeze ( features , dim=1 ) ,\r\n",
        "                                              self.compute_A ( features ) ).cpu ().detach ().numpy () )\r\n",
        "\r\n",
        "            input = Parameter ( torch.FloatTensor ( np.asarray ( gcn_feat ) ).cuda () )\r\n",
        "            input = torch.squeeze ( input )\r\n",
        "        # print(input)\r\n",
        "        combined = torch.cat ( (input , Hidden_State) , 1 )\r\n",
        "        f = torch.sigmoid ( self.fl ( combined ) )\r\n",
        "        i = torch.sigmoid ( self.il ( combined ) )\r\n",
        "        o = torch.sigmoid ( self.ol ( combined ) )\r\n",
        "        C = torch.tanh ( self.Cl ( combined ) )\r\n",
        "        Cell_State = f * Cell_State + i * C\r\n",
        "        Hidden_State = o * torch.tanh ( Cell_State )\r\n",
        "\r\n",
        "        return Hidden_State , Cell_State\r\n",
        "\r\n",
        "    def loop ( self, hidden_vec_from_encoder ):\r\n",
        "        batch_size = self.batch_size\r\n",
        "        time_step = self.time_step\r\n",
        "        if self.stream =='s2':\r\n",
        "            Cell_State, out, stream2_output = self.initHidden()\r\n",
        "        else:\r\n",
        "            Cell_State , out  = self.initHidden ()\r\n",
        "        mu1_all , mu2_all , sigma1_all , sigma2_all , rho_all = self.initMogParams()\r\n",
        "        for i in range ( time_step ):\r\n",
        "            if i == 0:\r\n",
        "                Hidden_State = hidden_vec_from_encoder\r\n",
        "            Hidden_State , Cell_State = self.forward( out , Hidden_State , Cell_State )\r\n",
        "            # print(Hidden_State.data)\r\n",
        "            mog_params = self.linear1(Hidden_State)\r\n",
        "            # mog_params = params.narrow ( -1 , 0 , params.size ()[ -1 ] - 1 )\r\n",
        "            out = mog_params\r\n",
        "            if self.stream == 's2':\r\n",
        "                stream2_output[:,i,:] = out\r\n",
        "            if self.stream == 's1':\r\n",
        "                mu_1 , mu_2 , log_sigma_1 , log_sigma_2 , pre_rho = mog_params.chunk ( 6 , dim=-1 )\r\n",
        "                rho = torch.tanh ( pre_rho )\r\n",
        "                log_sigma_1 = torch.exp(log_sigma_1)\r\n",
        "                log_sigma_2 = torch.exp(log_sigma_2)\r\n",
        "                mu1_all[:,i,:] = mu_1\r\n",
        "                mu2_all[:,i,:] = mu_2\r\n",
        "                sigma1_all[:,i,:] = log_sigma_1\r\n",
        "                sigma2_all[:,i,:] = log_sigma_2\r\n",
        "                rho_all[:,i,:] = rho\r\n",
        "            # print(mu1_all.grad_fn)\r\n",
        "            # out = self.sample(mu_1 , mu_2 , log_sigma_1 , log_sigma_2, rho)\r\n",
        "        if self.stream == 's1':\r\n",
        "            return Hidden_State , Cell_State, mu1_all , mu2_all , sigma1_all , sigma2_all , rho_all\r\n",
        "        else:\r\n",
        "            return stream2_output, Hidden_State , Cell_State , mu1_all , mu2_all , sigma1_all , sigma2_all , rho_all\r\n",
        "\r\n",
        "    def initHidden(self):\r\n",
        "        out = torch.randn(self.batch_size, self.num_mog_params, device=device) if self.stream == 's1' else torch.randn(self.batch_size, self.hidden_size, device=device)\r\n",
        "        if self.stream == 's2':\r\n",
        "            output =  torch.randn(self.batch_size, self.time_step, self.hidden_size, device=device)\r\n",
        "            return torch.randn(self.batch_size, self.hidden_size, device=device), out, output\r\n",
        "        else:\r\n",
        "            return torch.randn ( self.batch_size , self.hidden_size , device=device ) , out\r\n",
        "\r\n",
        "    def initMogParams(self):\r\n",
        "        mu1_all = torch.rand(self.batch_size, self.time_step, 1, device=device) * 1000\r\n",
        "        mu2_all = torch.rand(self.batch_size, self.time_step, 1, device=device) * 1000\r\n",
        "        sigma1_all = torch.rand(self.batch_size, self.time_step, 1, device=device) * 100\r\n",
        "        sigma2_all = torch.rand(self.batch_size, self.time_step, 1, device=device) * 100\r\n",
        "        rho_all = torch.randn(self.batch_size, self.time_step, 1, device=device)\r\n",
        "        \r\n",
        "        return mu1_all, mu2_all, sigma1_all, sigma2_all, rho_all"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}